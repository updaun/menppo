{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import os\r\n",
    "\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\r\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "actions = [\r\n",
    "    'easy',\r\n",
    "    'difficult'\r\n",
    "]\r\n",
    "\r\n",
    "data = np.concatenate([\r\n",
    "    np.load('dataset/seq_easy_1630941592.npy'),\r\n",
    "    np.load('dataset/seq_difficult_1630941592.npy')\r\n",
    "], axis=0)\r\n",
    "\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1102, 30, 1893)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "x_data = data[:, :, :-1]\r\n",
    "labels = data[:, 0, -1]\r\n",
    "\r\n",
    "print(x_data.shape)\r\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1102, 30, 1892)\n",
      "(1102,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from tensorflow.keras.utils import to_categorical\r\n",
    "\r\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\r\n",
    "y_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1102, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "x_data = x_data.astype(np.float32)\r\n",
    "y_data = y_data.astype(np.float32)\r\n",
    "\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=42)\r\n",
    "\r\n",
    "print(x_train.shape, y_train.shape)\r\n",
    "print(x_val.shape, y_val.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(991, 30, 1892) (991, 2)\n",
      "(111, 30, 1892) (111, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import LSTM, Dense\r\n",
    "\r\n",
    "model = Sequential([\r\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\r\n",
    "    Dense(32, activation='relu'),\r\n",
    "    Dense(len(actions), activation='softmax')\r\n",
    "])\r\n",
    "\r\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 64)                500992    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 503,138\n",
      "Trainable params: 503,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\r\n",
    "\r\n",
    "history = model.fit(\r\n",
    "    x_train,\r\n",
    "    y_train,\r\n",
    "    validation_data=(x_val, y_val),\r\n",
    "    epochs=200,\r\n",
    "    callbacks=[\r\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\r\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\r\n",
    "    ]\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "31/31 [==============================] - 3s 58ms/step - loss: 52.5025 - acc: 0.5156 - val_loss: 12.6379 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.32432, saving model to models\\model.h5\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 13.1516 - acc: 0.5832 - val_loss: 5.8600 - val_acc: 0.4955\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.32432 to 0.49550, saving model to models\\model.h5\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 1.9007 - acc: 0.5520 - val_loss: 0.6707 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.49550 to 0.55856, saving model to models\\model.h5\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.3943 - acc: 0.8163 - val_loss: 0.2396 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55856 to 0.95495, saving model to models\\model.h5\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2393 - acc: 0.9697 - val_loss: 0.2336 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95495\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.2001 - acc: 0.9758 - val_loss: 0.1972 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95495\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.1794 - acc: 0.9717 - val_loss: 0.1849 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95495 to 0.99099, saving model to models\\model.h5\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.1611 - acc: 0.9687 - val_loss: 0.1449 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99099\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1467 - acc: 0.9717 - val_loss: 0.1281 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99099\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.1291 - acc: 0.9738 - val_loss: 0.1217 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99099\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.1157 - acc: 0.9738 - val_loss: 0.1059 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99099\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.1097 - acc: 0.9748 - val_loss: 0.1055 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99099\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.1013 - acc: 0.9738 - val_loss: 0.0934 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99099\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0945 - acc: 0.9738 - val_loss: 0.0879 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99099\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0898 - acc: 0.9748 - val_loss: 0.0832 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99099\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.0872 - acc: 0.9748 - val_loss: 0.0862 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99099\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.0879 - acc: 0.9758 - val_loss: 0.0977 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99099\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.0855 - acc: 0.9758 - val_loss: 0.0773 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99099\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.0803 - acc: 0.9778 - val_loss: 0.0727 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99099\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0800 - acc: 0.9778 - val_loss: 0.0774 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99099\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0824 - acc: 0.9738 - val_loss: 0.0656 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99099\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0763 - acc: 0.9768 - val_loss: 0.0820 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99099\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 2s 48ms/step - loss: 0.0741 - acc: 0.9768 - val_loss: 0.0618 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99099\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0697 - acc: 0.9788 - val_loss: 0.0602 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99099\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0706 - acc: 0.9818 - val_loss: 0.0585 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99099\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0681 - acc: 0.9788 - val_loss: 0.0571 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.99099\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0695 - acc: 0.9788 - val_loss: 0.0557 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.99099\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0775 - acc: 0.9788 - val_loss: 0.0586 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99099\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0631 - acc: 0.9818 - val_loss: 0.0661 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99099\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0630 - acc: 0.9808 - val_loss: 0.0517 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99099\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0618 - acc: 0.9798 - val_loss: 0.0518 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99099\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0680 - acc: 0.9707 - val_loss: 0.0488 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99099\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0750 - acc: 0.9768 - val_loss: 0.0477 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99099\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0594 - acc: 0.9818 - val_loss: 0.0739 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99099\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0587 - acc: 0.9818 - val_loss: 0.0455 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99099\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0615 - acc: 0.9788 - val_loss: 0.0462 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.99099\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0649 - acc: 0.9778 - val_loss: 0.0490 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99099\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0809 - acc: 0.9788 - val_loss: 0.0499 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99099\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0550 - acc: 0.9808 - val_loss: 0.0446 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99099\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0665 - acc: 0.9778 - val_loss: 0.0404 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99099\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0550 - acc: 0.9788 - val_loss: 0.0440 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99099\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0516 - acc: 0.9808 - val_loss: 0.0428 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.99099\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0536 - acc: 0.9808 - val_loss: 0.0540 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99099\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0473 - acc: 0.9859 - val_loss: 0.0438 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.99099\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0453 - acc: 0.9818 - val_loss: 0.0356 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99099\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0694 - acc: 0.9778 - val_loss: 0.0379 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99099\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0495 - acc: 0.9808 - val_loss: 0.0338 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99099\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0466 - acc: 0.9818 - val_loss: 0.0398 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.99099\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0417 - acc: 0.9849 - val_loss: 0.0354 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99099\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0521 - acc: 0.9798 - val_loss: 0.0526 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99099\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0689 - acc: 0.9798 - val_loss: 0.0662 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.99099\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0557 - acc: 0.9808 - val_loss: 0.0591 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.99099\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0438 - acc: 0.9839 - val_loss: 0.0281 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.99099\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0531 - acc: 0.9788 - val_loss: 0.0386 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.99099\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0556 - acc: 0.9808 - val_loss: 0.0285 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.99099\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0411 - acc: 0.9849 - val_loss: 0.0273 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.99099\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0458 - acc: 0.9828 - val_loss: 0.0432 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.99099\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0342 - acc: 0.9859 - val_loss: 0.0240 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.99099\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0344 - acc: 0.9869 - val_loss: 0.0253 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.99099\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0389 - acc: 0.9889 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.99099 to 1.00000, saving model to models\\model.h5\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0374 - acc: 0.9839 - val_loss: 0.0256 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 1.00000\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0306 - acc: 0.9889 - val_loss: 0.0244 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 1.00000\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0301 - acc: 0.9879 - val_loss: 0.0223 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 1.00000\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0306 - acc: 0.9889 - val_loss: 0.0344 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 1.00000\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0286 - acc: 0.9909 - val_loss: 0.0216 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 1.00000\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0290 - acc: 0.9899 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 1.00000\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0291 - acc: 0.9899 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 1.00000\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0271 - acc: 0.9889 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 1.00000\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.0268 - acc: 0.9899 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 1.00000\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0280 - acc: 0.9899 - val_loss: 0.0195 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 1.00000\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0282 - acc: 0.9899 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 1.00000\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0247 - acc: 0.9909 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 1.00000\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0265 - acc: 0.9909 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 1.00000\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0240 - acc: 0.9919 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 1.00000\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0247 - acc: 0.9919 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 1.00000\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0267 - acc: 0.9909 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 1.00000\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0244 - acc: 0.9929 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 1.00000\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0278 - acc: 0.9899 - val_loss: 0.0430 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 1.00000\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0161 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 1.00000\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0235 - acc: 0.9919 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 1.00000\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0152 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 1.00000\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0221 - acc: 0.9950 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 1.00000\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0244 - acc: 0.9939 - val_loss: 0.0231 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 1.00000\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0213 - acc: 0.9929 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 1.00000\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0192 - acc: 0.9950 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 1.00000\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0195 - acc: 0.9950 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 1.00000\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 1.00000\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0173 - acc: 0.9950 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 1.00000\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.0170 - acc: 0.9960 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 1.00000\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 0.0184 - acc: 0.9960 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 1.00000\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0164 - acc: 0.9960 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 1.00000\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0155 - acc: 0.9970 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 1.00000\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0165 - acc: 0.9970 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 1.00000\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0162 - acc: 0.9980 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 1.00000\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0183 - acc: 0.9970 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 1.00000\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0177 - acc: 0.9950 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 1.00000\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0187 - acc: 0.9950 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 1.00000\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0144 - acc: 0.9990 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 1.00000\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0132 - acc: 0.9980 - val_loss: 0.0150 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 1.00000\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0137 - acc: 0.9970 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 1.00000\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0144 - acc: 0.9970 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 1.00000\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.0139 - acc: 0.9950 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 1.00000\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0116 - acc: 0.9990 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 1.00000\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0110 - acc: 0.9990 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 1.00000\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0120 - acc: 0.9990 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 1.00000\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0136 - acc: 0.9970 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 1.00000\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0108 - acc: 0.9990 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 1.00000\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 1.00000\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 1.00000\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0099 - acc: 0.9990 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0121 - acc: 0.9970 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 1.00000\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0093 - acc: 0.9990 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 1.00000\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0090 - acc: 0.9990 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 1.00000\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0086 - acc: 0.9990 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 1.00000\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 1.00000\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0086 - acc: 0.9990 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 1.00000\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 1.00000\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0092 - acc: 0.9990 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 1.00000\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 1.00000\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 1.00000\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 1.00000\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 1.00000\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 1.00000\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0089 - acc: 0.9990 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 1.00000\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0079 - acc: 0.9990 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 1.00000\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 1.00000\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 1.00000\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 1.00000\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 1.00000\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 1.00000\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 1.00000\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 1.00000\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 1.00000\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 1.00000\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 1.00000\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 1.00000\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 1.00000\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 1.00000\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 1.00000\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 1.00000\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 1.00000\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 1.00000\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 1.00000\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 1.00000\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 1.00000\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 1.00000\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 1.00000\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 1.00000\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 1.00000\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 1.00000\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 1.00000\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 1.00000\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 1.00000\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 1.00000\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 1.00000\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 1.00000\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 1.00000\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 1.00000\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 1.00000\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 1.00000\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 1.00000\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 1.00000\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 1.00000\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 1.00000\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 1.00000\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 1.00000\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 1.00000\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 1.00000\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 1.00000\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 1.00000\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 1.00000\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 1.00000\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 1.00000\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 1.00000\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 1.00000\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 1.00000\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 1.00000\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 1.00000\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 1.00000\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 1.00000\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 1.00000\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 1.00000\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 1.00000\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 1.00000\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 1.00000\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 1.00000\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 1.00000\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 1.00000\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 1.00000\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 1.00000\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 1.00000\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 1.00000\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 1.00000\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 1.00000\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 1.00000\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 1.00000\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 1.00000\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 1.00000\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 1.00000\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\r\n",
    "acc_ax = loss_ax.twinx()\r\n",
    "\r\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\r\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\r\n",
    "loss_ax.set_xlabel('epoch')\r\n",
    "loss_ax.set_ylabel('loss')\r\n",
    "loss_ax.legend(loc='upper left')\r\n",
    "\r\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\r\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\r\n",
    "acc_ax.set_ylabel('accuracy')\r\n",
    "acc_ax.legend(loc='upper left')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\r\n",
    "from tensorflow.keras.models import load_model\r\n",
    "\r\n",
    "model = load_model('models/model.h5')\r\n",
    "\r\n",
    "y_pred = model.predict(x_val)\r\n",
    "\r\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[56,  0],\n",
       "        [ 0, 55]],\n",
       "\n",
       "       [[55,  0],\n",
       "        [ 0, 56]]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "interpreter": {
   "hash": "bbc6ecb72ef9aab1ba0fcc0220f9f100166d86f33532edecf34b9fe6ae1fcfee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}